ğŸš€ CodeRAG: A Lightweight Retrieval-Augmented Code Intelligence System

A synthetic-dataâ€“driven RAG pipeline for code understanding and Text-to-SQL generation

CodeRAG is a compact but fully functional Retrieval-Augmented Generation (RAG) system built entirely on synthetic data created by us.
Inspired by the paper â€œTowards a Generalist Code Embedding Model Based on Massive Data Synthesisâ€, this project explores whether meaningful code embeddings and retrieval capabilities can be learned without large datasets or GPUs.

Despite running entirely on personal laptops, we designed and implemented a complete pipeline:

ğŸŒŸ Project Highlights
âœ… 1. Synthetic Dataset Generation

We generated four types of supervised code transformation tasks using a local LLM
(Qwen2.5-Coder-32B-Instruct-Q5_K_M.gguf):

Text-to-Code

Code-to-Text

Code-to-Code

Hybrid Transformations

From these, we curated a 40-sample high-quality dataset for training our encoder.

âœ… 2. Fine-Tuned Code Embedding Encoder

We fine-tuned a SentenceTransformer Bi-Encoder using contrastive learning (Multiple Negatives Ranking Loss).

Base model: BAAI/bge-code-large-en

Training script: train_full_encoder.py

Output directory: CodeRAG_encoder/

The encoder learns to map natural language queries and code snippets into a shared semantic space.

âœ… 3. Retrieval Index Creation (FAISS)

Using the gretelai/synthetic_text_to_sql dataset, we built a retrieval corpus for Text-to-SQL evaluation:

Embeddings stored using the fine-tuned encoder

FAISS index: sql_rag_faiss_index.bin

Mapping file: sql_rag_corpus_map.npy

Indexing handled by: vectorbase.py.

âœ… 4. RAG Pipeline for Text-to-SQL

The final pipeline retrieves relevant SQL examples and feeds them to a generation model:

Retrieval using our encoder + FAISS

Generation with Mistral-7B-Instruct-v0.2

Pipeline script: rag_query.py

RAG improves grounding, reduces hallucination, and stabilizes SQL generation.

ğŸ¯ Objective

To evaluate whether a small, synthetic dataset can train a useful code retriever that improves downstream Text-to-SQL generation in a RAG setup â€” even under severe hardware limitations.

ğŸ“‰ Limitations

Running Mistral-7B on CPU hardware made full benchmarking slow, so the complete 92-query evaluation set could not be executed within the project timeline.
However, qualitative tests show clear improvements in stability and correctness when retrieval is used.

ğŸ“‚ Repository Structure
â”œâ”€â”€ CodeRAG_Dataset.csv          # 40 synthetic training samples
â”œâ”€â”€ CodeRAG_encoder/             # Fine-tuned bi-encoder model
â”œâ”€â”€ train_full_encoder.py        # Encoder training script
â”œâ”€â”€ vectorbase.py                # Corpus indexing and FAISS builder
â”œâ”€â”€ rag_query.py                 # End-to-end RAG pipeline
â”œâ”€â”€ sql_rag_faiss_index.bin      # FAISS index
â”œâ”€â”€ sql_rag_corpus_map.npy       # Mapping of index â†’ text
â”œâ”€â”€ rag_evaluation_metrics.py    # Evaluation Script 
â””â”€â”€ README.md                    # Project documentation

ğŸ§­ How It Works

User enters a natural-language query (e.g., â€œGet all customers with orders > 50â€).

Query is embedded using the fine-tuned bi-encoder.

FAISS retrieves the most relevant SQL examples.

Retrieved context + query are passed to Mistral-7B.

Final SQL query is generated.

ğŸ™Œ Acknowledgements

This project is inspired by:
Towards a Generalist Code Embedding Model Based on Massive Data Synthesis (2024)
